# Reproducibility Protocol (PW-NER)

This document defines the **end-to-end reproducibility contract** for generating **PW-NER**
(silver-standard Persian named entity inventories) from the referenced Persian Wikipedia snapshot.

If you deviate from any item below (versions, normalization, input schema, QC thresholds),
assume outputs can change.

---

## 1. Scope

This repository supports reproducible generation of:

1) **Processed intermediate table** (`processed_data.csv`) containing per-document JSON-encoded NER outputs
2) **Per-class entity inventories** (`inventories/*.xlsx` or `inventories/*.csv`)
3) (Optional) **QC-separated inventories** (`clean/`, `flagged/`) and a `qc_report.json`
4) **Integrity artifacts** (SHA-256 checksums + machine-readable manifests)

---

## 2. Source Corpus (Immutable Reference)

- **Corpus:** Farsi Wikipedia (Kaggle)
- **Expected file:** `data/raw_data.csv`
- **Required columns (default):** `title`, `content`, `link`  
  (column names can be mapped via CLI flags; see below)
- **Snapshot used for the official release:** **1400/04/25** (see `data/README.md`)

The repository does **not** redistribute the raw corpus.

---

## 3. Environment Pinning (Non-Negotiable)

### 3.1 Python
- **Python:** `>=3.10,<3.13` (use the same major/minor version across runs)

### 3.2 Dependencies
Install pinned dependencies:
```bash
pip install -r requirements.txt
```

### 3.3 Stanza Model Version
Stanza models can change over time. Record (at minimum):
- Stanza version (from `requirements.txt`)
- model language: `fa`
- CPU-only inference (recommended)

---

## 4. Deterministic Execution Settings

### 4.1 CPU-only
Run Stanza inference CPU-only for stability across machines.

### 4.2 Stable manifests
By default, manifests may include timestamps for auditability.
For **fully deterministic manifests**, run with `--no_timestamp`.

---

## 5. Normalization Contract (Offsets Depend On This)

All outputs depend on the exact preprocessing contract:

1) HTML stripping policy (BeautifulSoup)
2) Hazm normalization configuration (**explicitly configured and recorded**)
3) Whitespace normalization policy (collapse consecutive whitespace → single space, strip)

If any of these change, extracted strings can change.

---

## 6. Output Contract

A recommended working directory layout:

```
PW-NER/
  processed_data.csv
  inventories/
    pers.xlsx
    loc.xlsx
    org.xlsx
    fac.xlsx
    pro.xlsx
    event.xlsx
  run_manifest.json
  progress.txt
```

> Note: `inventories/` is generated by the pipeline when `--export_inventories` is enabled.

---

## 7. End-to-End Reproduction Steps

### Step A — Obtain the corpus
1) Download the Kaggle dataset (“Farsi Wikipedia”)
2) Save as:
   - `data/raw_data.csv`
3) Ensure UTF-8 encoding

### Step B — Run extraction + inventory export (end-to-end)
Run:

```bash
python pipeline.py \
  --input data/raw_data.csv \
  --output_dir PW-NER \
  --chunksize 5000 \
  --batch_size 250 \
  --text_field both \
  --export_inventories \
  --inventories_format xlsx
```

Optional (for deterministic manifest files):
```bash
python pipeline.py ... --no_timestamp
```

If your CSV columns differ, map them explicitly:
```bash
python pipeline.py \
  --input data/raw_data.csv \
  --output_dir PW-NER \
  --title_column title \
  --content_column content \
  --link_column link \
  --export_inventories
```

### Step C — Run QC (optional)
QC expects the inventory directory as input:

```bash
python qc.py \
  --input_dir PW-NER/inventories \
  --output_dir PW-NER/qc \
  --write_raw_copy
```

Optional (for deterministic QC reports):
```bash
python qc.py ... --no_timestamp
```

### Step D — Integrity (recommended for releases)
Generate deterministic checksums for published artifacts:

```bash
python scripts/make_checksums.py --root artifacts --out artifacts/checksums_sha256.txt
```

Verify later:

```bash
python scripts/make_checksums.py --root artifacts --out artifacts/checksums_sha256.txt --verify
```

---

## 8. What “Reproducible” Means Here

Given:
- identical corpus snapshot
- identical pinned dependencies
- identical normalization config
- identical pipeline/QC flags

Then you should obtain:
- identical inventory counts
- identical `inventories/*` file hashes (if exported in the same format)
- identical QC splits and QC report statistics
